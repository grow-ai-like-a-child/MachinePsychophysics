
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
  <!-- â€”â€” Meta â€”â€” -->
  <!-- â€”â€” Meta â€”â€” -->
  <meta name="description" content="Large-scale psychophysics study shows emergent cognitive-control signatures in 108 Visionâ€“Language Models across 2 220 trials (+ 238 control).">
  <meta property="og:title" content="Machine Psychophysics: Cognitive Control in Visionâ€“Language Models">
  <meta property="og:description" content="108 VLMs Ã— 2 220 trials (plus 238 control) reveal human-aligned congruency effects and persistent hierarchical-conflict deficits.">
  <meta property="og:url" content="https://github.com/grow-ai-like-a-child/Psychophysics.git">
  <meta property="og:image" content="standard_vs_squared.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta name="twitter:title" content="Machine Psychophysics: Cognitive Control in VLMs">
  <meta name="twitter:description" content="Emergent executive-function signatures and scaling trends across 108 VLMs.">
  <meta name="twitter:image" content="standard_vs_squared.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Machine Psychophysics: Cognitive Control in Visionâ€“Language Models</title>

  <!-- Fonts & Bulma -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma-carousel@4.0.3/dist/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <!-- libs -->
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/js/all.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/bulma-carousel@4.0.3/dist/js/bulma-carousel.min.js"></script>

<style>
  :root {
    --bg-main: #ffffff;
    --text-main: #1a1a1a;
  }
  [data-theme="dark"] {
    --bg-main: #181818;
    --text-main: #1a1a1a; /* ä¿æŒæ–‡å­—é¢œè‰²ä¸€è‡´ */
  }

  html {
    scroll-behavior: smooth;
  }

  body {
    background: var(--bg-main);
    color: var(--text-main);
    font-family: "Noto Sans", sans-serif;
  }

  /* Navbar å›ºå®š */
  .navbar {
    position: sticky;
    top: 0;
    z-index: 20;
    background: var(--bg-main);
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.06);
  }

  .hero-body {
    padding: 3rem 1.5rem;
  }

  .title.is-1 {
    font-size: 2.5rem !important;
  }
  @media (min-width: 1024px) {
    .title.is-1 {
      font-size: 3rem !important;
    }
  }
  @media (min-width: 1440px) {
    .title.is-1 {
      font-size: 3.5rem !important;
    }
  }

  /* æ·±è‰²æ¨¡å¼æ ‡é¢˜ä¿®æ­£ */
  [data-theme="dark"] .title {
    color: #ffffff !important;
  }

  /* Hero is-light æ·±è‰²èƒŒæ™¯ä¿®æ­£ */
  [data-theme="dark"] .hero.is-light {
    background: #1e1e1e !important;
    color: #e5e5e5 !important;
  }

  /* å¼ºè°ƒæ–‡å­—ä¿®æ­£ */
  [data-theme="dark"] p strong,
  [data-theme="dark"] li strong,
  [data-theme="dark"] figcaption strong {
    color: #1a1a1a !important;
  }
  [data-theme="dark"] figcaption {
    color: #444 !important;
  }

  /* âœ… å…³é”®æ¨¡å—å¡ç‰‡æ ·å¼ç»Ÿä¸€ */
  .gradient-box {
    position: relative;
    color: #1a1a1a !important;
    background: #f5f5f5;
    padding: 1.2rem 1.5rem;
    border-radius: 12px;
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.06);
    transition: all 0.2s ease;
  }

  .gradient-box::before {
    content: "";
    position: absolute;
    inset: 0;
    border-radius: inherit;
    background: rgba(0, 0, 0, 0.05);
    mix-blend-mode: multiply;
    pointer-events: none;
  }

  [data-theme="dark"] .gradient-box {
    background: #f5f5f5 !important;
    color: #1a1a1a !important;
    text-shadow: none !important;
  }

  /* âœ… ä¿è¯å¡ç‰‡æ–‡å­—ç»Ÿä¸€é—´è· */
  .gradient-box p strong {
    display: inline-block;
    font-size: 1.1rem;
    margin-top: -0.2rem;
    margin-bottom: 0.6rem;
  }

  /* âœ… ç­‰é«˜å¸ƒå±€æ”¯æŒ */
  .equal-height-columns {
    display: flex;
    flex-wrap: wrap;
  }

  .equal-height-columns .column {
    display: flex;
  }

  .equal-height-columns .box {
    flex: 1;
    display: flex;
    flex-direction: column;
    justify-content: center;
    min-height: 240px;
  }

  /* å›¾ç‰‡æ ·å¼ */
  .carousel img,
  figure img {
    border-radius: 8px;
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.08);
  }

  figure figcaption {
    margin-top: 6px;
    font-size: 0.8rem;
    color: #666;
    text-align: center;
  }

  /* ä½œè€…éƒ¨åˆ† */
  .affiliation {
    font-weight: normal;
    font-size: 0.9em;
    color: #888;
    margin-left: 4px;
  }

  a[title] {
    text-decoration: none;
    border-bottom: 1px dashed #ccc;
    cursor: help;
  }

  [data-theme="dark"] a[title] {
    border-bottom-color: #666;
  }

  [data-theme="dark"] .affiliation {
    color: #aaa;
  }

  /* BibTeX æ‹·è´æŒ‰é’® */
  .copy-btn {
    position: absolute;
    top: 8px;
    right: 8px;
    border: none;
    background: #3273dc;
    color: #fff;
    border-radius: 4px;
    font-size: 0.8rem;
    padding: 4px 8px;
    cursor: pointer;
  }

  /* Footer æ·±è‰²ä¿®æ­£ */
  [data-theme="dark"] .footer {
    background-color: #181818 !important;
    color: #e5e5e5 !important;
  }

  [data-theme="dark"] .footer a {
    color: #a0c8ff !important;
  }

  /* å»æ‰ design ä¸­ä¸‹åˆ’çº¿ */
  #design u {
    text-decoration: none;
  }
</style>




<!-- Sticky Nav -->
<nav class="navbar" role="navigation">
  <div class="container is-max-desktop" style="justify-content:space-between">
    <div class="navbar-brand">
      <a class="navbar-item" href="#">VLM-Psychophysics</a>
      <a role="button" class="navbar-burger" data-target="navMenu">
        <span></span><span></span><span></span>
      </a>
    </div>
    <div id="navMenu" class="navbar-menu">
      <a class="navbar-item" href="#abstract">Abstract</a>
      <a class="navbar-item" href="#design">Design</a>
      <a class="navbar-item" href="#results">Results</a>
      <a class="navbar-item" href="#BibTeX">BibTeX</a>
    </div>
</nav>

<!-- Hero -->
<section id="top" class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop has-text-centered">
      <h1 class="title is-1">ğŸ§  Machine Psychophysics: Cognitive Control in Visionâ€“Language Models</h1>

      <p class="is-size-5">
        <a href="https://ihzedoul.com/" target="_blank">Dezhi Luo<sup>1</sup></a>,
        <a href="https://openreview.net/profile?id=%7EMaijunxian_Wang1" target="_blank">Maijunxian Wang<sup>2</sup></a>,
        <a href="https://openreview.net/profile?id=%7EBingyang_Wang2" target="_blank">Bingyang Wang<sup>3</sup></a>,<br>
        <a href="https://openreview.net/profile?id=~Tianwei_Zhao1" target="_blank">Tianwei Zhao<sup>4</sup></a>,
        <a href="https://williamium3000.github.io/" target="_blank">Yijiang Li<sup>5</sup></a>,
        <a href="https://hokindeng.github.io/" target="_blank">Hokin Deng<sup>6</sup></a>
      </p>

      <p class="is-size-6">
        <sup>1</sup>University of Michigan &nbsp;&nbsp;
        <sup>2</sup>University of California, Davis &nbsp;&nbsp;
        <sup>3</sup>Emory University<br>
        <sup>4</sup>Johns Hopkins University &nbsp;&nbsp;
        <sup>5</sup>University of California, San Diego &nbsp;&nbsp;
        <sup>6</sup>Carnegie Mellon University
      </p>
      
      <div class="has-text-centered" style="margin-top: 0.8rem;">
        <img src="growai.png" alt="GrowAI Logo" style="height: 36px; vertical-align: middle; margin-right: 8px;">
        <strong>GrowAI Team</strong> â€”
        <a href="https://growing-ai-like-a-child.github.io/" target="_blank" style="color: #3273dc;">
          growing-ai-like-a-child.github.io
        </a>
      </div>

      <p style="margin-top:15px">
        <a class="button is-dark is-rounded" href="https://arxiv.org/abs/2505.18969" target="_blank">
          <span class="icon"><i class="fas fa-file-pdf"></i></span><span>Paper</span>
        </a>
        <a class="button is-dark is-rounded" href="https://github.com/grow-ai-like-a-child/Psychophysics" target="_blank">
          <span class="icon"><i class="fab fa-github"></i></span><span>Code & Dataset</span>
        </a>
      </p>
    </div>
  </div>
</section>


<!-- Teaser -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="notification is-primary is-light" style="font-size:1.1rem">
      <strong>TL;DR</strong> 108 VLMs reproduce classic congruency effects on Stroop & Flanker tasks, yet collapse on hierarchical â€œSquaredâ€ conflicts â€” robust executive control still lags behind even in the largest models.
    </div>
  </div>
</section>

<!-- Abstract -->
<section id="abstract" class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p><strong>Cognitive control</strong> refers to the ability to flexibly coordinate thought and action. Conflict-task paradigms benchmark this faculty by contrasting congruent and incongruent trials.</p>
          <p>We conduct the first <strong>large-scale psychophysics evaluation</strong> of Visionâ€“Language Models, testing <strong>108 models</strong> on Stroop, Letter- and Number-Flanker tasks plus their more demanding â€œ<em>Squared</em>â€ variants â€” <strong>across 2 220 trials, plus 238 control trials</strong>.</p>
          <p>Models show human-like congruency patterns, yet collapse when conflicts are hierarchical. Accuracy grows <em>roughly log-linearly</em> with parameter count, echoing resource-limited curves in human forced-response studies.</p>
          <p>The benchmark demonstrates that executive-function signatures can emerge from general-purpose learning at scale while revealing clear gaps for future research.</p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Key Findings -->
<!-- Key Findings -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered" style="margin-top:2rem;">ğŸ” Key Findings</h2>

      <div class="columns is-multiline equal-height-columns is-centered">
        <div class="column is-half">
          <div class="box gradient-box" style="background:linear-gradient(135deg,#b3cde0 0%,#ccebc5 100%);">
            <h3 class="title is-4"><i class="fas fa-sliders-h"></i> Emergent Congruency</h3>
            <p>All models reproduce the classic congruency effect, indicating interference resolution emerges from multimodal pre-training.</p>
          </div>
        </div>
        <div class="column is-half">
          <div class="box gradient-box" style="background:linear-gradient(135deg,#decbe4 0%,#fed9a6 100%);">
            <h3 class="title is-4"><i class="fas fa-layer-group"></i> Hierarchical Interference</h3>
            <p>Squared tasks introduce nested conflicts still unsolved by top-tier systems.</p>
          </div>
        </div>
        <div class="column is-half">
          <div class="box gradient-box" style="background:linear-gradient(135deg,#ffffcc 0%,#ccebc5 100%);">
            <h3 class="title is-4"><i class="fas fa-chart-line"></i> Scaling Trend</h3>
            <p>Performance rises <strong>roughly log-linearly</strong> from 1 B â†’ 110 B parameters, paralleling human processing-time curves.</p>
          </div>
        </div>
        <div class="column is-half">
          <div class="box gradient-box" style="background:linear-gradient(135deg,#fbb4ae 0%,#fddaec 100%);">
            <h3 class="title is-4"><i class="fas fa-check-double"></i> Convergent Validity</h3>
            <p>Letter- and Number-Flanker scores strongly covary, confirming a unified control construct.</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Experiment Overview -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">ğŸ§ª Experiment Overview</h2>

    <div class="columns is-multiline is-centered" style="margin-bottom: 2rem;">
      <!-- Card 1: Model Count -->
      <div class="column is-one-third has-text-centered">
        <div class="has-text-weight-bold is-size-1" style="color: #e74c3c;">108</div>
        <div class="has-text-weight-semibold">Visionâ€“Language Models</div>
        <div class="is-size-7 has-text-grey">1Bâ€“110B parameters</div>
      </div>

      <!-- Card 2: Trial Count -->
      <div class="column is-one-third has-text-centered">
        <div class="has-text-weight-bold is-size-1" style="color: #27ae60;">2,220</div>
        <div class="has-text-weight-semibold">Conflict Trials</div>
        <div class="is-size-7 has-text-grey">Stroop, Flanker, Squared</div>
      </div>

      <!-- Card 3: Effect Prevalence -->
      <div class="column is-one-third has-text-centered">
        <div class="has-text-weight-bold is-size-1" style="color: #2980b9;">&gt;95%</div>
        <div class="has-text-weight-semibold">Show Conflict Effect</div>
        <div class="is-size-7 has-text-grey">Performance drop: C &gt; I</div>
      </div>
    </div>

    <p class="has-text-centered is-size-5">
      Our large-scale battery tested <strong>108 visionâ€“language models</strong> across <strong>2,220 structured trials</strong>, revealing that <strong>over 95% of models</strong> exhibit cognitive conflict effects.
    </p>
  </div>
</section>


  
<!-- Experimental Design -->
<section id="design" class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered" style="margin-top:2rem;">ğŸ”¬ Experimental Design</h2>
      <div class="content has-text-justified" style="max-width:800px;margin:0 auto 1.5rem">
        <p><strong>We evaluate cognitive control in VLMs with a three-tier battery.</strong>
          <br><b>(1) Standard tasks</b> reproduce classic Stroop and Flanker paradigms â€” models must ignore irrelevant colour or flanker cues in simple congruent vs. incongruent trials. <u>They include <strong>84 Stroop</strong> (42&nbsp;C/42&nbsp;I) and <strong>180 Letter- / 180 Number-Flanker</strong> (90&nbsp;C/90&nbsp;I) stimuli.</u>
          <br><b>(2) Squared tasks</b> add a second layer of conflict, yielding four hierarchical conditions (FC, FI, SCRI, SIRC) that tax executive control far beyond the standard benchmark. <u>This yields <strong>336 Stroop-Squared</strong> and <strong>720 stimuli for each Flanker-Squared task</strong>.</u>
          <br><b>(3) Control battery</b> disentangles low-level demands by isolating OCR, colour perception, and 2-D spatial encoding, ensuring that any deficits arise from representational conflict rather than perception per se. <u>It contains <strong>238 control trials</strong>.</u>
        </p>
      </div>

      <div id="methodology-carousel" class="carousel results-carousel">
        <div class="item">
          <figure>
            <img loading="lazy" src="figure1.png" alt="Standard tasks examples">
            <figcaption><strong>Standard Tasks.</strong> 84 Stroop + 180 Ã— 2 Flanker stimuli.</figcaption>
          </figure>
        </div>
        <div class="item">
          <figure>
            <img loading="lazy" src="figure2.png" alt="Squared tasks conditions">
            <figcaption><strong>Squared Tasks.</strong> 336 Stroop-Squared + 720 Ã— 2 Flanker-Squared stimuli.</figcaption>
          </figure>
        </div>
        <div class="item">
          <figure>
            <img loading="lazy" src="control_tasks.png" alt="Control battery">
            <figcaption><strong>Control Battery.</strong> 238 trials disentangling OCR, colour, spatial encoding.</figcaption>
          </figure>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Results -->
<section id="results" class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">ğŸ“Š Results</h2>
    <div class="content has-text-justified">
      <h3 class="title is-4">Highlights</h3>
      <ul>
        <li>Standard tasks reproduce classic congruency patterns.</li>
        <li>Squared tasks expose substantial hierarchical-interference cost.</li>
        <li>Control battery confirms deficits stem from conflict, not perception.</li>
        <li>Performance improves steadily with parameter count.</li>
      </ul>

      <figure style="text-align:center;margin:2rem 0">
        <img loading="lazy" src="standard_vs_squared.png" alt="Overall accuracy" style="max-width:95%">
        <figcaption><strong>Overall Results.</strong> Human-model accuracy across conflict conditions.</figcaption>
      </figure>

      <h4 class="title is-5">Scaling with parameters</h4>
      <p style="max-width:720px;margin:0 auto 1rem">
        Model size acts as a proxy for available computational resources. Accuracy grows <strong>roughly log-linearly</strong> from 1&nbsp;B to 110&nbsp;B parameters, yet even the largest models fall short of human performance on hierarchical conflict.
      </p>

      <figure style="text-align:center">
        <img loading="lazy" src="scaling.png" alt="Scaling curve" style="max-width:90%">
        <figcaption><strong>Scaling Trend.</strong> Accuracy vs. parameter count (1&nbsp;B â†’ 110&nbsp;B).</figcaption>
      </figure>

<!-- Result Summary Section -->
<section style="margin-top: 3rem;">
  <h3 class="title is-4 has-text-centered">Result Summary</h3>
  <div class="columns is-multiline is-centered equal-height-columns">

    <div class="column is-half">
      <div class="box gradient-box solid-style" style="background:#fceabb;">
        <p><strong>Congruency Effect</strong><br>
        >95% models show conflict interference.<br>
        Stroop: t = 8.99, p < 10â»Â¹â´<br>
        Flanker-L: t = 17.88, p < 10â»Â³Â³<br>
        Flanker-N: t = 16.85, p < 10â»Â³Â¹</p>
      </div>
    </div>

    <div class="column is-half">
      <div class="box gradient-box solid-style" style="background:#d5f4e6;">
        <p><strong>Squared Conflict</strong><br>
        Fully-incongruent (SIRC) trials show largest drop. All p < 0.001</p>
      </div>
    </div>

    <div class="column is-half">
      <div class="box gradient-box solid-style" style="background:#e2f0cb;">
        <p><strong>Control Accuracy</strong><br>
        Accuracy â‰ˆ 85% on 238 control trials (OCR, color, spatial).</p>
      </div>
    </div>

    <div class="column is-half">
      <div class="box gradient-box solid-style" style="background:#fcd5ce;">
        <p><strong>Task Concordance</strong><br>
        r = 0.96 between Letter-/Number-Flanker â†’ shared bottleneck</p>
      </div>
    </div>

  </div>
</section>

          
<section id="implications" class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">ğŸ§­ Implications & Future Work</h2>

    <div class="content has-text-justified" style="max-width: 880px; margin: 0 auto;">
      
      <h3 class="title is-5">ğŸ§  Implications for Cognitive AI</h3>
      <ul>
        <li><strong>Emergent Congruency:</strong> The classic Stroop and Flanker effects emerge even in untrained models, suggesting interference control arises from foundational pretraining dynamics.</li>
        <li><strong>Limits of Scaling:</strong> Even 110B-parameter models fail on deeply nested conflicts, pointing to architectural or training regime bottlenecks beyond sheer size.</li>
        <li><strong>Shared Control Mechanisms:</strong> Strong correlations between letter- and number-Flanker scores (r = 0.96) support the idea of a unified control construct within VLMs.</li>
      </ul>

      <h3 class="title is-5">ğŸ” Open Questions</h3>
      <ul>
        <li>How do specific aspects of pretraining data influence the emergence of conflict control?</li>
        <li>What inductive biases or training interventions are needed to overcome hierarchical interference?</li>
        <li>Can VLMs develop temporally extended control structures analogous to executive functions?</li>
      </ul>

      <h3 class="title is-5">ğŸ§ª Methodological Contribution</h3>
      <p>
        This study introduces a psychophysics-inspired paradigm for evaluating control behavior in VLMs. 
        By using tightly controlled stimuli and separating standard vs. hierarchical conflict, we provide 
        mechanistic insights and open a new path toward studying cognitive control in AI systems.
      </p>
    </div>
  </div>
</section>


  
<!-- BibTeX -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content" style="position:relative">
    <h2 class="title">BibTeX</h2>
    <button class="copy-btn" id="copyBtn">Copy</button>
<pre><code id="bibtex">
@article{luo2025machine,
  title   = {Machine Psychophysics: Cognitive Control in Visionâ€“Language Models},
  author  = {Luo, Dezhi and Wang, Maijunxian and Wang, Bingyang and Zhao, Tianwei and Li, Yijiang and Deng, Hokin},
  publisher={arXiv Preprints},
  year    = {2025},
  url     = {https://arxiv.org/abs/2505.18969}
}
</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p class="has-text-centered">
        <img src="growai.png" alt="GrowAI Logo" style="height: 60px; margin-bottom: 0.5rem;"><br>
        <strong>GrowAI Team</strong> â€”
        <a href="https://growing-ai-like-a-child.github.io/" target="_blank" style="color: #3273dc;">
          growing-ai-like-a-child.github.io
        </a>
      </p>
      <p style="font-size:.9rem">Page adapted from 
        <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>. 
        Licensed under <a href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">CC BY-SA 4.0</a>.
      </p>
    </div>
  </div>
</footer>

<!-- JS -->
<script>
  /* burger */
  const burger=document.querySelector('.navbar-burger');
  burger.onclick=()=>{burger.classList.toggle('is-active');document.getElementById(burger.dataset.target).classList.toggle('is-active');};

  /* theme */
  const root=document.documentElement,btn=document.getElementById('theme-toggle');
  if(localStorage.theme==='dark'){root.dataset.theme='dark';btn.innerHTML='<span class="icon"><i class="fas fa-sun"></i></span>';}
  btn.onclick=()=>{const dark=root.dataset.theme==='dark';root.dataset.theme=dark?'light':'dark';
    btn.innerHTML=dark?'<span class="icon"><i class="fas fa-moon"></i></span>':'<span class="icon"><i class="fas fa-sun"></i></span>';
    localStorage.theme=root.dataset.theme;};

  /* copy bib */
  document.getElementById('copyBtn').onclick=()=>{
    navigator.clipboard.writeText(document.getElementById('bibtex').innerText).then(()=>{
      const b=document.getElementById('copyBtn');b.textContent='Copied!';setTimeout(()=>b.textContent='Copy',1500);
    });
  };

  /* carousel */
  document.addEventListener('DOMContentLoaded',()=>bulmaCarousel.attach());
</script>
</body>
</html>
