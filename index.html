<!DOCTYPE html>
<html>
<head>
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
  <meta charset="utf-8">

  <!-- ‚Äî‚Äî‚Äî Meta ‰ø°ÊÅØÔºàSEO & SocialÔºâ ‚Äî‚Äî‚Äî -->
  <meta name="description"
        content="Large-scale psychophysics study shows emergent cognitive-control signatures in 108 Vision‚ÄìLanguage Models via Stroop & Flanker conflict tasks.">
  <meta property="og:title"
        content="Machine Psychophysics: Cognitive Control in Vision‚ÄìLanguage Models"/>
  <meta property="og:description"
        content="108 VLMs √ó 2 220 trials reveal human-aligned congruency effects and persistent hierarchical-conflict deficits."/>
  <meta property="og:url" content="https://vlm-psychophysics.github.io/"/>
  <meta property="og:image" content="standard_vs_squared.png"/>
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title"
        content="Machine Psychophysics: Cognitive Control in VLMs">
  <meta name="twitter:description"
        content="Emergent executive-function signatures and scaling trends across 108 VLMs.">
  <meta name="twitter:image" content="standard_vs_squared.png">
  <meta name="twitter:card" content="summary_large_image">

  <meta name="keywords"
        content="Vision-Language Models, Cognitive Control, Conflict Tasks, Psychophysics, AI Evaluation">
  <meta name="author"
        content="Dezhi Luo, Maijunxian Wang, Bingyang Wang, Tianwei Zhao, Yijiang Li, Hokin Deng (GrowAI Team)">
  <meta name="robots" content="index, follow">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Machine Psychophysics: Cognitive Control in Vision‚ÄìLanguage Models</title>

  <!-- Ê†∑Âºè & ËµÑÊ∫ê -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma-carousel@4.0.3/dist/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/js/all.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/bulma-carousel@4.0.3/dist/js/bulma-carousel.min.js"></script>

  <!-- MathJax -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <style>
    .carousel .item{display:flex;flex-direction:column;justify-content:center;align-items:center}
    .carousel .item>figure{margin:0}
    .carousel img{max-height:450px;object-fit:contain}
    .hero-body{padding:3rem 1.5rem}
    .title.is-1{font-size:2.5rem!important}
    @media(min-width:1024px){.title.is-1{font-size:3rem!important}}
    .publication-title{margin-bottom:1rem!important}
    .author-block{margin-right:1rem}
    figure figcaption{margin-top:6px;font-size:.8rem;color:#666;text-align:center;}
  </style>
</head>
<body>

<!-- ===== Hero ===== -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <div style="display:flex;align-items:center;justify-content:center;margin-bottom:20px;">
            <h1 class="title is-1 publication-title">
              üß† Machine Psychophysics: Cognitive Control in Vision‚ÄìLanguage Models
            </h1>
          </div>
          <h4 class="title is-size-4 publication-title" style="color:red;">
            NeurIPS&nbsp;2025<span style="font-weight:normal;font-style:italic;"> (Submitted)</span>
          </h4>

          <!-- Authors -->
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="#" target="_blank">Dezhi&nbsp;Luo</a><sup>1</sup>,</span>
            <span class="author-block"><a href="#" target="_blank">Maijunxian&nbsp;Wang</a><sup>2</sup>,</span>
            <span class="author-block"><a href="#" target="_blank">Bingyang&nbsp;Wang</a><sup>3</sup>,</span>
            <span class="author-block"><a href="#" target="_blank">Tianwei&nbsp;Zhao</a><sup>4</sup>,</span>
            <span class="author-block"><a href="#" target="_blank">Yijiang&nbsp;Li</a><sup>5</sup>,</span>
            <span class="author-block"><a href="#" target="_blank">Hokin&nbsp;Deng</a><sup>6</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <sup>1</sup>Michigan,
              <sup>2</sup>UC Davis,
              <sup>3</sup>Emory,
              <sup>4</sup>JHU,<br>
              <sup>5</sup>UCSD,
              <sup>6</sup>CMU
            </span><br>
            <span class="author-block" style="color:#4a4a4a;margin-top:10px;">
              üå± <strong>GrowAI Team</strong> ‚Äì <a href="https://growing-ai-like-a-child.github.io/"
                target="_blank" style="color:#3273dc;">growing-ai-like-a-child.github.io</a>
            </span>
          </div>

          <!-- Links -->
          <div class="column has-text-centered">
            <div class="publication-links">

              <!-- Paper -->
              <span class="link-block">
                <a href="https://osf.io/preprints/osf/uve6p_v1" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span><span>Paper</span>
                </a>
              </span>

              <!-- Code & Dataset -->
              <span class="link-block">
                <a href="https://github.com/grow-ai-like-a-child/Psychophysics" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span><span>Code & Dataset</span>
                </a>
              </span>

            </div>
          </div>
          <!-- /Links -->

        </div>
      </div>
    </div>
  </div>
</section>
<!-- ===== /Hero ===== -->

<!-- ===== Teaser ===== -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="notification is-primary is-light" style="font-size:1.1rem;">
      <strong>TL;DR&nbsp;</strong>
      108 Vision‚ÄìLanguage Models reproduce classic congruency effects on Stroop &amp; Flanker tasks,
      yet collapse on hierarchical ‚ÄúSquared‚Äù conflicts ‚Äî revealing that robust executive control
      has not yet scaled with model size.
    </div>
  </div>
</section>
<!-- ===== /Teaser ===== -->

<!-- ===== Abstract ===== -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p><strong>Cognitive control</strong> refers to the ability to flexibly coordinate thought and action. Conflict-task paradigms benchmark this faculty by contrasting congruent and incongruent trials.</p>
          <p>We conduct the first <strong>large-scale psychophysics evaluation</strong> of Vision‚ÄìLanguage Models, testing <strong>108 models</strong> on Stroop, Letter- and Number-Flanker tasks plus their more demanding ‚Äú<em>Squared</em>‚Äù variants ‚Äî <strong>2 220 trials</strong> each.</p>
          <p>Models show human-like congruency patterns, yet collapse when conflicts are hierarchical. Accuracy grows monotonically with parameter count, echoing resource-limited curves in human forced-response studies.</p>
          <p>The benchmark demonstrates that executive-function signatures can emerge from general-purpose learning at scale while revealing clear gaps for future research.</p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- ===== /Abstract ===== -->

<!-- ===== Key Findings ===== -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered" style="margin-top:2rem;">üîç Key Findings</h2>

      <div class="columns is-multiline">
        <div class="column is-half">
          <div class="box" style="height:100%;background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:white;">
            <h3 class="title is-4" style="color:white;"><i class="fas fa-sliders-h"></i> Emergent Congruency</h3>
            <p>All models reproduce the classic congruency effect, indicating interference resolution emerges from multimodal pre-training.</p>
          </div>
        </div>
        <div class="column is-half">
          <div class="box" style="height:100%;background:linear-gradient(135deg,#ffecd2 0%,#fcb69f 100%);">
            <h3 class="title is-4"><i class="fas fa-layer-group"></i> Hierarchical Interference</h3>
            <p>Squared tasks introduce nested conflicts still unsolved by top-tier systems.</p>
          </div>
        </div>
        <div class="column is-half">
          <div class="box" style="height:100%;background:linear-gradient(135deg,#a8edea 0%,#fed6e3 100%);">
            <h3 class="title is-4"><i class="fas fa-chart-line"></i> Scaling Trend</h3>
            <p>Performance rises monotonically from ~1 B to 110 B parameters, paralleling human processing-time curves.</p>
          </div>
        </div>
        <div class="column is-half">
          <div class="box" style="height:100%;background:linear-gradient(135deg,#ff9a9e 0%,#fecfef 100%);">
            <h3 class="title is-4"><i class="fas fa-check-double"></i> Convergent Validity</h3>
            <p>Letter- and Number-Flanker scores strongly covary, confirming a unified control construct.</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- ===== /Key Findings ===== -->

<!-- ===== Experimental Design Carousel ===== -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered" style="margin-top:2rem;">üî¨ Experimental Design</h2>
      <!-- Intro paragraph for the three-task battery -->
      <div class="content has-text-justified" style="max-width:800px;margin:0 auto 1.5rem;">
        <p><strong>We evaluate cognitive control in VLMs with a three-tier battery.</strong>
          <br><b>(1) Standard&nbsp;tasks</b> reproduce classic Stroop and Flanker paradigms‚Äîmodels must ignore irrelevant colour or flanker cues in simple congruent vs.&nbsp;incongruent trials.
          <br><b>(2) Squared&nbsp;tasks</b> add a second layer of conflict, yielding four hierarchical conditions (FC, FI, SCRI, SIRC) that tax executive control far beyond the standard benchmark.
          <br><b>(3) The control battery</b> disentangles low-level demands by isolating OCR, colour perception, and 2-D spatial encoding, ensuring that any deficits arise from representational conflict rather than perception per&nbsp;se.
        </p>
      </div>


      <div id="methodology-carousel" class="carousel results-carousel">

        <!-- Standard tasks -->
        <div class="item">
          <figure>
            <img src="figure1.png" alt="Standard tasks">
            <figcaption><strong>Standard Tasks.</strong> Congruent vs. incongruent Stroop &amp; Flanker stimuli.</figcaption>
          </figure>
        </div>

        <!-- Squared tasks -->
        <div class="item">
          <figure>
            <img src="figure2.png" alt="Squared tasks">
            <figcaption><strong>Squared Tasks.</strong> Four hierarchical conflict conditions (FC / FI / SCRI / SIRC).</figcaption>
          </figure>
        </div>

        <!-- Control battery -->
        <div class="item">
          <figure>
            <img src="control_tasks.png" alt="Control tasks">
            <figcaption><strong>Control Battery.</strong> Isolates OCR, color perception, spatial encoding.</figcaption>
          </figure>
        </div>

      </div>
    </div>
  </div>
</section>
<!-- ===== /Experimental Design Carousel ===== -->

<!-- ===== Results ===== -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">üìä Results</h2>
    <div class="content has-text-justified">

      <h3 class="title is-4">Highlights</h3>
      <ul>
        <li>Standard tasks reproduce classic congruency patterns.</li>
        <li>Squared tasks expose substantial hierarchical-interference cost.</li>
        <li>Control battery confirms deficits stem from conflict, not perception.</li>
        <li>Performance improves steadily with parameter count.</li>
      </ul>

      <!-- Main accuracy figure -->
      <figure style="text-align:center;margin:2rem 0;">
        <img src="standard_vs_squared.png" alt="Main accuracy results" style="max-width:95%;">
        <figcaption><strong>Overall Results.</strong> Human-model accuracy across conflict conditions.</figcaption>
      </figure>

      <!-- Scaling curve -->
      <h4 class="title is-5">Scaling with parameters</h4>

      <p style="max-width:720px;margin:0 auto 1rem;text-align:center;">
        Model size acts as a proxy for available computational resources.
        Accuracy grows roughly log-linearly from 1 B to 110 B parameters,
        yet even the largest models fall short of human performance on hierarchical
        conflict. The curve closely resembles the resource‚Äìperformance trade-off
        measured with processing time in human psychophysics.
      </p>
      
      <figure style="text-align:center;">
        <img src="scaling.png" alt="Scaling curve" style="max-width:90%;">
        <figcaption><strong>Scaling Trend.</strong> Accuracy vs. parameter count (1 B ‚Üí 110 B).</figcaption>
      </figure>

    </div>
  </div>
</section>
<!-- ===== /Results ===== -->

<!-- ===== Implications ===== -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">üí° Implications & Future Work</h2>

    <div class="columns is-multiline">
      <div class="column is-half">
        <div class="box" style="border-left:4px solid #ff6b6b;">
          <h3 class="title is-4"><i class="fas fa-exclamation-triangle" style="color:#ff6b6b;"></i> Open Challenges</h3>
          <ul>
            <li>Robust resolution of multi-level conflicts.</li>
            <li>Generalisation to unseen layouts.</li>
            <li>Efficiency ‚Äî control gains scale slowly with parameters.</li>
            <li>Interpretability of internal gating.</li>
          </ul>
        </div>
      </div>

      <div class="column is-half">
        <div class="box" style="border-left:4px solid #48c774;">
          <h3 class="title is-4"><i class="fas fa-lightbulb" style="color:#ffdd57;"></i> Research Directions</h3>
          <ul>
            <li>Add <em>control heads</em> / PFC-style routing.</li>
            <li>Conflict-aware curricula &amp; delayed-reward RL.</li>
            <li>Synthetic psychophysics corpora at scale.</li>
            <li>Forced-response benchmarks linking params ‚Üí PT.</li>
          </ul>
        </div>
      </div>

      <div class="column is-full">
        <div class="box" style="background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);color:white;">
          <h3 class="title is-4" style="color:white;"><i class="fas fa-bullseye"></i> Toward Executive-Aware Models</h3>
          <p style="font-size:1.1rem;">
            Our benchmark shows that today‚Äôs VLMs master perception yet still struggle with self-regulation.
            We release tasks, code, and scoring tools to spur progress on dynamic cognitive-control diagnostics.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- ===== /Implications ===== -->

<!-- ===== BibTeX ===== -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
@article{luo2025machine,
  title   = {Machine Psychophysics: Cognitive Control in Vision‚ÄìLanguage Models},
  author  = {Luo, Dezhi and Wang, Maijunxian and Wang, Bingyang and Zhao, Tianwei and Li, Yijiang and Deng, Hokin},
  journal = {Neural Information Processing Systems (NeurIPS)},
  year    = {2025},
  note    = {Submitted},
  url     = {https://vlm-psychophysics.github.io}
}
    </code></pre>
  </div>
</section>
<!-- ===== /BibTeX ===== -->

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content has-text-centered">
          <p><strong>üå± GrowAI Team</strong><br>
            <a href="https://growing-ai-like-a-child.github.io/" target="_blank">
              growing-ai-like-a-child.github.io
            </a>
          </p>
          <p style="font-size:0.9rem;">
            Page adapted from the
            <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">
              Academic Project Page Template
            </a>. Source licensed under
            <a href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">
              CC BY-SA 4.0
            </a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<script>
document.addEventListener('DOMContentLoaded', () => {
  bulmaCarousel.attach();
});
</script>

</body>
</html>
