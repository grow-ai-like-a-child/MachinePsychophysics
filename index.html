
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Machine Psychophysics ‚Äì GrowAI</title>
  <style>
    body {
      font-family: 'Arial', sans-serif;
      margin: 0;
      padding: 0;
      background-color: #ffffff;
      color: #111;
      line-height: 1.7;
    }

    .section {
      padding: 3rem 1rem;
    }

    .hero {
      background: linear-gradient(to right, #f0f4ff, #f8f9ff);
      padding: 3rem 1rem;
      text-align: center;
    }

    h1, h2, h3 {
      font-weight: bold;
      text-align: center;
      margin: 0.5em auto;
    }

    p {
      max-width: 800px;
      margin: 1em auto;
      padding: 0 1em;
      text-align: justify;
    }

    .container {
      max-width: 1024px;
      margin: 0 auto;
      padding: 0 1rem;
    }

    .columns {
      display: flex;
      flex-wrap: wrap;
      margin: 0 -1rem;
    }

    .column {
      flex: 1;
      min-width: 280px;
      padding: 1rem;
    }

    .box {
      background: #f9f9f9;
      border-radius: 6px;
      padding: 1.5rem;
      box-shadow: 0 2px 6px rgba(0,0,0,0.05);
    }

    img {
      max-width: 100%;
      height: auto;
      display: block;
      margin: 2em auto;
      border-radius: 6px;
      box-shadow: 0 0 8px rgba(0, 0, 0, 0.1);
    }

    .is-light {
      background-color: #f5f6fa;
    }

    .centered {
      text-align: center;
    }

    .button {
      display: inline-block;
      padding: 0.6em 1.2em;
      background-color: #3273dc;
      color: white;
      text-decoration: none;
      border-radius: 4px;
      margin: 0.5em;
    }

    footer {
      text-align: center;
      font-size: 0.9em;
      color: #666;
      padding: 2em 1em;
      margin-top: 2em;
      background: #f8f8f8;
    }

    @media screen and (max-width: 768px) {
      .columns {
        flex-direction: column;
      }
    }
  </style>

<style>
  .dark-mode {
    background-color: #121212;
    color: #f0f0f0;
  }
  .dark-mode .box {
    background: #1e1e1e;
    border: 1px solid #333;
  }
  .dark-mode a {
    color: #80b3ff;
  }
  .dark-mode pre {
    background: #222;
    color: #eee;
  }
  .dark-toggle {
    position: fixed;
    top: 1rem;
    right: 1rem;
    z-index: 1000;
    padding: 0.5em 1em;
    border-radius: 5px;
    background: #333;
    color: #fff;
    border: none;
    cursor: pointer;
  }
</style>

<script>
  function toggleDarkMode() {
    const body = document.body;
    const isDark = body.classList.toggle("dark-mode");
    localStorage.setItem("theme", isDark ? "dark" : "light");
  }

  document.addEventListener("DOMContentLoaded", () => {
    if (localStorage.getItem("theme") === "dark") {
      document.body.classList.add("dark-mode");
    }
  });
</script>
</head>
<body>
<button class="dark-toggle" onclick="toggleDarkMode()">üåó Toggle Dark Mode</button>

<section class="hero">
  <h1>Machine Psychophysics</h1>
  <h2>Cognitive Control in Vision‚ÄìLanguage Models</h2>
  <p class="centered">
    <a class="button" href="psychophysics_paper.pdf">üìÑ Paper</a>
    <a class="button" href="https://github.com/grow-ai-like-a-child/MachinePsychophysics">üíª Code</a>
    <a class="button" href="#bibtex">üìö BibTeX</a>
  </p>
</section>


<section class="section">
  <div class="container">
    <h2>Full Method & Results</h2>
    <div class="box">
      <h3>üìê Methodology</h3>
      <p>We implemented classic cognitive control tasks (Stroop, Flanker) and their squared variants to assess interference resolution capabilities of 108 VLMs. Control tasks isolated perceptual abilities. All data were synthetic and standardized across conditions.</p>
      <p>The squared tasks introduce response-level and stimulus-level incongruities. Each model saw 2,220 trials. Four conflict conditions were evaluated: Fully Congruent (FC), Fully Incongruent (FI), Stimulus-Congruent/Response-Incongruent (SCRI), and Stimulus-Incongruent/Response-Congruent (SIRC).</p>
    </div>
    <div class="box">
      <h3>üìà Results Summary</h3>
      <p>Models demonstrated human-like congruency effects on standard tasks. Squared variants increased difficulty and revealed strong model-specific differences. Model performance improved with parameter count. Larger models more reliably ignored irrelevant input features and prioritized task-relevant cues.</p>
    </div>
    <div class="box">
      <h3>üß† Discussion</h3>
      <p>These findings suggest that cognitive control mechanisms may emerge from scaling. However, squared tasks still induce significant failures, even for top-tier models. Control limitations remain in layered interference scenarios. This has implications for building more robust AI systems capable of human-level generalization.</p>
    </div>
    <div class="box">
      <h3>üî¨ Conclusion</h3>
      <p>Machine Psychophysics introduces a new way to evaluate foundational models. Our framework offers both diagnostic and theoretical insight into AI‚Äôs capacity for flexible, goal-directed processing. We hope this benchmark guides future VLM research toward more cognitively aligned systems.</p>
    </div>
  </div>
</section>
<section class="section is-light">
  <div class="container">
    <h2>Overview</h2>
    <div class="columns">
      <div class="column">
        <div class="box">
          <h3>üß† Motivation</h3>
          <p>
            Can vision-language models (VLMs) replicate human-like cognitive control behavior? 
            Inspired by classic psychophysics, we evaluate 108 VLMs on Stroop, Flanker, and "squared" tasks.
          </p>
        </div>
      </div>
      <div class="column">
        <div class="box">
          <h3>üìä Scale & Results</h3>
          <p>
            Our benchmark reveals robust congruency effects, scaling patterns, and model-specific differences in resolving conflict across tasks.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container">
    <section class="section is-light"><div class="container"><div class="box"><div class="box" style="background: linear-gradient(135deg, #e0f7fa 0%, #80deea 100%);"><h2 class="title is-3 has-text-centered">üî¨ Methods</h2>
    
    <div class="box">
      <img src="figure1.png" alt="Standard Tasks: Stroop and Flanker">
      <h3 class="subtitle is-5 has-text-centered">üß™ Standard Tasks: Stroop and Flanker</h3>
      <p class="has-text-grey">Models were asked to respond to color or character targets while ignoring incongruent distractors. These tasks simulate selective attention and interference resolution, commonly used in human psychophysics.</p>
    </div>
     alt="Stroop and Flanker Tasks">
    
    <div class="box">
      <img src="figure2.png" alt="Squared Tasks with Hierarchical Conflict">
      <h3 class="subtitle is-5 has-text-centered">üß™ Squared Tasks: Hierarchical Conflict</h3>
      <p class="has-text-grey">Squared versions introduce conflicts on both stimulus and response levels, increasing cognitive load. This design elicits greater variability and highlights models' failure under layered interference.</p>
    </div>
     alt="Squared Tasks">
    <h3>Squared Tasks</h3>
    </div></div></section>
<section class="section"><div class="container"><div class="box"><div class="box" style="background: linear-gradient(135deg, #ede7f6 0%, #d1c4e9 100%);"><h2 class="title is-3 has-text-centered">üìä Results</h2>
    
    <div class="box">
      <img src="standard_vs_squared.png" alt="Comparison of standard vs squared task conditions">
      <h3 class="subtitle is-5 has-text-centered">üìä Condition-wise Accuracy</h3>
      <p class="has-text-grey">Performance dropped significantly from standard to squared conditions. Fully incongruent (FI) and stimulus-congruent/response-incongruent (SCRI) were especially difficult for most models.</p>
    </div>
     alt="Standard vs Squared Tasks">
    
    <div class="box">
      <img src="control_tasks.png" alt="Control Tasks Isolating Perceptual Demands">
      <h3 class="subtitle is-5 has-text-centered">üéØ Control Tasks</h3>
      <p class="has-text-grey">To isolate sources of difficulty, we tested models on color recognition, word reading, and spatial queries in isolation‚Äîconfirming their perceptual capacities were not the limiting factor in conflict tasks.</p>
    </div>
     alt="Control Task Variants">
    <h3>Control Tasks</h3>
    
    <div class="box">
      <img src="scaling.png" alt="Scaling Effects on Cognitive Control Tasks">
      <h3 class="subtitle is-5 has-text-centered">üìà Model Scaling vs Performance</h3>
      <p class="has-text-grey">Larger models like GPT-4V and Claude-3 outperformed smaller ones on incongruent and squared tasks, showing an emergent ability to suppress irrelevant inputs‚Äîsuggesting control can arise from scale.</p>
    </div>
     alt="Scaling and Model Size">
    <h3>Scaling and Model Size</h3>
  </div>
</section>

<section class="section is-light">
  <div class="container">
    </div></div></section>
<section class="section"><div class="container"><div class="box"><div class="box" style="background: linear-gradient(135deg, #fbe9e7 0%, #ffab91 100%);"><h2 class="title is-3 has-text-centered">üìö BibTeX</h2>
    <pre><code>@inproceedings{wang2025psychophysics,
  title={{Machine Psychophysics: Cognitive Control in Vision-Language Models}},
  author={{Luo, Dezhi and Wang, Maijunxian and Wang, Bingyang and Zhao, Tianwei and Li, Yijiang and Deng, Hokin}},
  booktitle={{NeurIPS}},
  year={{2025}}
}</code></pre>
  </div>
</section>

<footer>
  &copy; {year} GrowAI Team. No framework, pure HTML + mimicked Bulma.
</div></div></div></section>
<footer>

</body>
</html>
